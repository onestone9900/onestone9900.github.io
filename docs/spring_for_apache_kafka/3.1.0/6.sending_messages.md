---
layout: default
title: Sending Messages
parent: 3.1.0
grand_parent: SpringForApacheKafka
nav_order: 6
---

- [Sending Messages 원문](https://docs.spring.io/spring-kafka/reference/kafka/sending-messages.html)


# 메세지 보내기(Sending Messages)
이 장에서는 메시지를 보내는 방법을 다룬다.


## KafkaTemplate 사용(Using KafkaTemplate)
이 장에서는 `KafkaTemplate`을 사용하여 메시지를 보내는 방법을 다룬다.


## 개요(Overview)
`KafkaTemplate`은 프로듀서를 래핑하고 카프카 토픽에 데이터를 보내는 편리한 방법을 제공한다. 다음 목록은 `KafkaTemplate`의 관련 메서드를 보여준다.

```java
CompletableFuture<SendResult<K, V>> sendDefault(V data);

CompletableFuture<SendResult<K, V>> sendDefault(K key, V data);

CompletableFuture<SendResult<K, V>> sendDefault(Integer partition, K key, V data);

CompletableFuture<SendResult<K, V>> sendDefault(Integer partition, Long timestamp, K key, V data);

CompletableFuture<SendResult<K, V>> send(String topic, V data);

CompletableFuture<SendResult<K, V>> send(String topic, K key, V data);

CompletableFuture<SendResult<K, V>> send(String topic, Integer partition, K key, V data);

CompletableFuture<SendResult<K, V>> send(String topic, Integer partition, Long timestamp, K key, V data);

CompletableFuture<SendResult<K, V>> send(ProducerRecord<K, V> record);

CompletableFuture<SendResult<K, V>> send(Message<?> message);

Map<MetricName, ? extends Metric> metrics();

List<PartitionInfo> partitionsFor(String topic);

<T> T execute(ProducerCallback<K, V, T> callback);

<T> T executeInTransaction(OperationsCallback<K, V, T> callback);

// Flush the producer.
void flush();

interface ProducerCallback<K, V, T> {

    T doInKafka(Producer<K, V> producer);

}

interface OperationsCallback<K, V, T> {

    T doInOperations(KafkaOperations<K, V> operations);

}
```

자세한 내용은 [Javadoc](https://docs.spring.io/spring-kafka/api/org/springframework/kafka/core/KafkaTemplate.html)을 참고하자.

{: .important}
버전 3.0에서는, 이전에 `ListenableFuture`를 반환했던 메서드가 `CompletableFuture`를 반환하도록 변경됐다. 마이그레이션을 용이하게 하기 위해 2.9 버전에는 `CompletableFuture` 반환 타입과 동일한 메서드를 제공하는 `CompletableFuture()`를 사용하는 메서드가 추가됐다. 이 방법은 더 이상 사용할 수 없다.

`sendDefault` API를 사용하려면 기본 토픽이 템플릿에 제공되어야 한다.

API는 타임스탬프(timestamp)를 파라미터로 사용하고 이 타임스탬프를 레코드에 저장한다. 사용자가 제공한 타임스탬프가 저장되는 방식은 카프카 토픽에 구성된 타임스탬프 타입에 따라 다르다. `CREATE_TIME`을 사용하도록 토픽가 구성된 경우 사용자가 지정한 타임스탬프가 기록된다(또는 지정되지 않은 경우 생성된다). `LOG_APPEND_TIME`을 사용하도록 토픽을 구성한 경우 사용자가 지정한 타임스탬프는 무시되고 브로커는 로컬 브로커 시간을 추가한다.

`metrics` 및 `partitionsFor` 메서드는 기본 [프로듀서](https://kafka.apache.org/20/javadoc/org/apache/kafka/clients/producer/Producer.html)의 동일한 메서드에 위임한다. `execute` 메소드는 기본 [프로듀서](https://kafka.apache.org/20/javadoc/org/apache/kafka/clients/producer/Producer.html)에 대한 직접 접근을 제공한다.

템플릿을 사용하려면, 프로듀서 팩토리를 구성하고 이를 템플릿 생성자에 제공하면 된다. 다음 예제에서 그 방법을 보여준다.

```java
@Bean
public ProducerFactory<Integer, String> producerFactory() {
    return new DefaultKafkaProducerFactory<>(producerConfigs());
}

@Bean
public Map<String, Object> producerConfigs() {
    Map<String, Object> props = new HashMap<>();
    props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092");
    props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, IntegerSerializer.class);
    props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
    // 더 많은 프로퍼티 정보는 다음을 참고하자. https://kafka.apache.org/documentation/#producerconfigs
    return props;
}

@Bean
public KafkaTemplate<Integer, String> kafkaTemplate() {
    return new KafkaTemplate<Integer, String>(producerFactory());
}
```

버전 2.5부터, 이제 팩토리의 `ProducerConfig` 프로퍼티를 오버라이드하여 동일한 팩토리의 다양한 프로듀서 구성으로 템플릿을 생성할 수 있다.

```java
@Bean
public KafkaTemplate<String, String> stringTemplate(ProducerFactory<String, String> pf) {
    return new KafkaTemplate<>(pf);
}

@Bean
public KafkaTemplate<String, byte[]> bytesTemplate(ProducerFactory<String, byte[]> pf) {
    return new KafkaTemplate<>(pf,
            Collections.singletonMap(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, ByteArraySerializer.class));
}
```

`ProducerFactory<?, ?>` 타입(예: 스프링 부트에 의해 자동 구성된 빈)의 빈은 다른 일반 타입으로 참조될 수 있다.

표준 `<bean/>` 정의를 사용하여 템플릿을 구성할 수도 있다.

그 다음 템플릿을 사용하려면, 해당 메서드 중 하나를 호출하면 된다.

When you use the methods with a Message<?> parameter, the topic, partition, key and timestamp information is provided in a message header that includes the following items:

`Message<?>` 파라미터와 함께 메소드를 사용하면 토픽, 파티션, 키 및 타임스탬프 정보가 다음 항목을 포함하는 메시지 헤더에 제공된다.

- `KafkaHeaders.TOPIC`
- `KafkaHeaders.PARTITION`
- `KafkaHeaders.KEY`
- `KafkaHeaders.TIMESTAMP`

메시지 페이로드는 데이터다.

선택적으로, `Future`가 완료될 때까지 기다리는 대신 전송 결과(성공 또는 실패)와 함께 비동기(asynchronous) 콜백을 가져오도록 `ProducerListener`를 사용하여 `KafkaTemplate`을 구성할 수 있다. 다음 목록은 `ProducerListener` 인터페이스의 정의를 보여준다.

```java
public interface ProducerListener<K, V> {

    void onSuccess(ProducerRecord<K, V> producerRecord, RecordMetadata recordMetadata);

    void onError(ProducerRecord<K, V> producerRecord, RecordMetadata recordMetadata, Exception exception);

}
```

기본적으로, 템플릿은 오류를 기록하고 전송이 성공하면 아무 작업도 수행하지 않는 `LoggingProducerListener`로 구성된다.

편의를 위해 메소드 중 하나만 구현하려는 경우 기본 메소드 구현이 제공된다.

`send` 메소드는 `CompletableFuture<SendResult>`를 반환한다. 전송 결과를 비동기적으로 수신하기 위해 리스너에 콜백을 등록할 수 있다. 다음 예제에서는 그 방법을 보여준다.

```java
CompletableFuture<SendResult<Integer, String>> future = template.send("myTopic", "something");
future.whenComplete((result, ex) -> {
    ...
});
```

`SendResult`에는 `ProducerRecord`와 `RecordMetadata`라는 두 가지 프로퍼티가 있다. 해당 객체에 대한 자세한 내용은 카프카 API 설명서를 참고하자.

`Throwable`은 `KafkaProducerException`으로 캐스팅할 수 있다. `failedProducerRecord` 프로퍼티에는 실패한 레코드가 포함되어 있다.

결과를 기다리기 위해 전송 스레드를 차단하려면 `future`의 `get()` 메서드를 호출할 수 있다. 제한 시간이 있는 방법을 사용하는 것이 좋다. `linger.ms`를 설정한 경우 기다리기 전에 `flush()`를 호출할 수 있다. 또는 편의를 위해 템플릿에는 보낼 때마다 템플릿이 `flush()`되도록 하는 `autoFlush` 파라미터가 있는 생성자가 있다. `flush`는 `linger.ms` 프로듀서 프로퍼티을 설정하고 부분 배치를 즉시 보내려는 경우에만 필요하다.


## 예제(Examples)
이 절에서는 카프카에 메시지를 보내는 예제를 보여준다.

예제 1. 논 블록킹 (Async)

```java
public void sendToKafka(final MyOutputData data) {
    final ProducerRecord<String, String> record = createRecord(data);

    CompletableFuture<SendResult<Integer, String>> future = template.send(record);
    future.whenComplete((result, ex) -> {
        if (ex == null) {
            handleSuccess(data);
        }
        else {
            handleFailure(data, record, ex);
        }
    });
}
```

예제 2. 블로킹 (Sync)

```java
public void sendToKafka(final MyOutputData data) {
    final ProducerRecord<String, String> record = createRecord(data);

    try {
        template.send(record).get(10, TimeUnit.SECONDS);
        handleSuccess(data);
    }
    catch (ExecutionException e) {
        handleFailure(data, record, e.getCause());
    }
    catch (TimeoutException | InterruptedException e) {
        handleFailure(data, record, e);
    }
}
```

`ExecutionException`의 원인은 `failedProducerRecord` 프로퍼티가 있는 `KafkaProducerException`이다.


## RoutingKafkaTemplate 사용(Using RoutingKafkaTemplate)
버전 2.5부터, `RoutingKafkaTemplate`을 사용하여 대상 토픽명을 기반으로 런타임 시 프로듀서를 선택할 수 있다.

{: .important }
>라우팅 템플릿은 `transactions`, `execute`, `flush` 또는 `metrics` 작업에 대한 토픽이 알려져 있지 않기 때문에 해당 작업을 지원하지 않는다.

템플릿에는 `java.util.regex.Pattern`과 `ProducerFactory<Object, Object>` 인스턴스 매핑이 필요하다. 이 맵은 순서대로 탐색되므로 순서가 지정되어야 한다(예: `LinkedHashMap`). 처음에는 좀 더 구체적인 패턴을 추가해야 한다.


다음의 간단한 스프링 부트 애플리케이션은 동일한 템플릿과 다른 시리얼라이저를 사용하여 다양한 토픽으로 보내는 방법에 대한 예제를 제공한다.

```java
@SpringBootApplication
public class Application {

    public static void main(String[] args) {
        SpringApplication.run(Application.class, args);
    }

    @Bean
    public RoutingKafkaTemplate routingTemplate(GenericApplicationContext context, ProducerFactory<Object, Object> pf) {
        // 다른 시리얼라이저를 사용하여, PF를 복제하고 종료를 위해 스프링에 등록한다.
        Map<String, Object> configs = new HashMap<>(pf.getConfigurationProperties());
        configs.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, ByteArraySerializer.class);
        DefaultKafkaProducerFactory<Object, Object> bytesPF = new DefaultKafkaProducerFactory<>(configs);
        context.registerBean("bytesPF", DefaultKafkaProducerFactory.class, () -> bytesPF);

        Map<Pattern, ProducerFactory<Object, Object>> map = new LinkedHashMap<>();
        map.put(Pattern.compile("two"), bytesPF);
        map.put(Pattern.compile(".+"), pf); // 스트링 시리얼라이저와 기본 PF
        return new RoutingKafkaTemplate(map);
    }

    @Bean
    public ApplicationRunner runner(RoutingKafkaTemplate routingTemplate) {
        return args -> {
            routingTemplate.send("one", "thing1");
            routingTemplate.send("two", "thing2".getBytes());
        };
    }

}
```

이 예제에 해당하는 `@KafkaListeners`는 어노테이션 프로퍼티에 표시된다.

비슷한 결과를 얻기 위한 다른 기술을 사용하되 동일한 토픽에 다른 타입을 보내는 추가 기능을 보려면 시리얼라이저 및 디시리얼라이저 위임을 참고하자.


## DefaultKafkaProducerFactory 사용(Using DefaultKafkaProducerFactory)
카프카템플릿(KafkaTemplate) 사용에서 볼 수 있듯이, 프로듀서팩토리(ProducerFactory)를 사용하여 프로듀서를 생성한다.

트랜잭션을 사용하지 않는 경우 기본적으로 `DefaultKafkaProducerFactory`는 `KafkaProducer` 자바독(JavaDocs)에서 권장하는 대로, 모든 클라이언트에서 사용하는 싱글톤 프로듀서를 생성한다. 그러나, 템플릿에서 `flush()`를 호출하면 동일한 프로듀서를 사용하는 다른 스레드에 대한 지연이 발생할 수 있다. 버전 2.3부터 `DefaultKafkaProducerFactory`에는 `producerPerThread`라는 새로운 프로퍼티가 있다. `true`로 설정하면 팩토리는 이 문제를 방지하기 위해 각 스레드에 대해 별도의 프로듀서를 생성(및 캐시)한다.

{: .important}
`producerPerThread`가 `true`인 경우, 프로듀서가 더 이상 필요하지 않을 때, 사용자 코드는 팩토리에서 `closeThreadBoundProducer()`를 호출한다. 그러면 프로듀서가 물리적으로 닫히고 `ThreadLocal`에서 제거된다. `reset()` 또는 `destroy()`를 호출해도 이러한 프로듀서는 정리되지 않는다.

KafkaTemplate 트랜잭션 및 비트랜잭션 게시도 참고하자.


`DefaultKafkaProducerFactory`를 생성할 때, 프로퍼티 맵만 가져오는 프로듀서를 호출하여 키 및/또는 값 `Serializer` 클래스를 구성에서 선택하거나(`KafkaTemplate` 사용의 예제 참고) `Serializer` 인스턴스를 `DefaultKafkaProducerFactory` 생성자에 전달할 수 있다( 이 경우 모든 프로듀서 는 동일한 인스턴스를 공유한다.) 또는 각 프로듀서에 대해 별도 `Serializer` 인스턴스를 얻는 데 사용되는 `Manufacturer<Serializer>`(버전 2.3부터)를 제공할 수 있다.

```java
@Bean
public ProducerFactory<Integer, CustomValue> producerFactory() {
    return new DefaultKafkaProducerFactory<>(producerConfigs(), null, () -> new CustomValueSerializer());
}

@Bean
public KafkaTemplate<Integer, CustomValue> kafkaTemplate() {
    return new KafkaTemplate<Integer, CustomValue>(producerFactory());
}
```

버전 2.5.10부터 이제 팩토리가 생성된 후 프로듀서 프로퍼티를 업데이트할 수 있다. 예를 들어 자격 증명이 변경된 후 SSL 키/신뢰 리포지터리 위치를 업데이트해야 하는 경우 유용할 수 있다. 변경 사항은 기존 프로듀서 인스턴스에 영향을 미치지 않는다. 새로운 프로퍼티를 사용하여 새 프로듀서가 생성되도록 `reset()`을 호출하여 기존 프로듀서를 모두 닫는다. 노트: 트랜젝셔널 프로듀서 팩토리를 논트랜잭셔널 프로듀서 팩토리로 변경할 수 없으며 그 반대의 경우도 마찬가지다.

이제 두 가지 새로운 방법이 제공된다.

```java
void updateConfigs(Map<String, Object> updates);

void removeConfig(String configKey);
```

버전 2.8부터 시리얼라이저를 객체로 제공하는 경우(생성자(constructor)에서 또는 설정자(setters)를 통해) 팩토리는 구성 프로퍼티로 구성하기 위해 `configure()` 메서드를 호출합니다.