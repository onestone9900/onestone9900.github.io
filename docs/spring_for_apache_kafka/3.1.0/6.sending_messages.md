---
layout: default
title: Sending Messages
parent: 3.1.0
grand_parent: SpringForApacheKafka
nav_order: 6
---

- [Sending Messages 원문](https://docs.spring.io/spring-kafka/reference/kafka/sending-messages.html)


# 메세지 보내기(Sending Messages)
이 장에서는 메시지를 보내는 방법을 다룬다.


## KafkaTemplate 사용(Using KafkaTemplate)
이 장에서는 `KafkaTemplate`을 사용하여 메시지를 보내는 방법을 다룬다.


## 개요(Overview)
`KafkaTemplate`은 프로듀서를 래핑하고 카프카 토픽에 데이터를 보내는 편리한 방법을 제공한다. 다음 목록은 `KafkaTemplate`의 관련 메서드를 보여준다.

```java
CompletableFuture<SendResult<K, V>> sendDefault(V data);

CompletableFuture<SendResult<K, V>> sendDefault(K key, V data);

CompletableFuture<SendResult<K, V>> sendDefault(Integer partition, K key, V data);

CompletableFuture<SendResult<K, V>> sendDefault(Integer partition, Long timestamp, K key, V data);

CompletableFuture<SendResult<K, V>> send(String topic, V data);

CompletableFuture<SendResult<K, V>> send(String topic, K key, V data);

CompletableFuture<SendResult<K, V>> send(String topic, Integer partition, K key, V data);

CompletableFuture<SendResult<K, V>> send(String topic, Integer partition, Long timestamp, K key, V data);

CompletableFuture<SendResult<K, V>> send(ProducerRecord<K, V> record);

CompletableFuture<SendResult<K, V>> send(Message<?> message);

Map<MetricName, ? extends Metric> metrics();

List<PartitionInfo> partitionsFor(String topic);

<T> T execute(ProducerCallback<K, V, T> callback);

<T> T executeInTransaction(OperationsCallback<K, V, T> callback);

// Flush the producer.
void flush();

interface ProducerCallback<K, V, T> {

    T doInKafka(Producer<K, V> producer);

}

interface OperationsCallback<K, V, T> {

    T doInOperations(KafkaOperations<K, V> operations);

}
```

자세한 내용은 [Javadoc](https://docs.spring.io/spring-kafka/api/org/springframework/kafka/core/KafkaTemplate.html)을 참고하자.

{: .important}
버전 3.0에서는, 이전에 `ListenableFuture`를 반환했던 메서드가 `CompletableFuture`를 반환하도록 변경됐다. 마이그레이션을 용이하게 하기 위해 2.9 버전에는 `CompletableFuture` 반환 타입과 동일한 메서드를 제공하는 `CompletableFuture()`를 사용하는 메서드가 추가됐다. 이 방법은 더 이상 사용할 수 없다.

`sendDefault` API를 사용하려면 기본 토픽이 템플릿에 제공되어야 한다.

API는 타임스탬프(timestamp)를 파라미터로 사용하고 이 타임스탬프를 레코드에 저장한다. 사용자가 제공한 타임스탬프가 저장되는 방식은 카프카 토픽에 구성된 타임스탬프 타입에 따라 다르다. `CREATE_TIME`을 사용하도록 토픽가 구성된 경우 사용자가 지정한 타임스탬프가 기록된다(또는 지정되지 않은 경우 생성된다). `LOG_APPEND_TIME`을 사용하도록 토픽을 구성한 경우 사용자가 지정한 타임스탬프는 무시되고 브로커는 로컬 브로커 시간을 추가한다.

`metrics` 및 `partitionsFor` 메서드는 기본 [프로듀서](https://kafka.apache.org/20/javadoc/org/apache/kafka/clients/producer/Producer.html)의 동일한 메서드에 위임한다. `execute` 메소드는 기본 [프로듀서](https://kafka.apache.org/20/javadoc/org/apache/kafka/clients/producer/Producer.html)에 대한 직접 접근을 제공한다.

템플릿을 사용하려면, 프로듀서 팩토리를 구성하고 이를 템플릿 생성자에 제공하면 된다. 다음 예제에서 그 방법을 보여준다.

```java
@Bean
public ProducerFactory<Integer, String> producerFactory() {
    return new DefaultKafkaProducerFactory<>(producerConfigs());
}

@Bean
public Map<String, Object> producerConfigs() {
    Map<String, Object> props = new HashMap<>();
    props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092");
    props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, IntegerSerializer.class);
    props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
    // 더 많은 프로퍼티 정보는 다음을 참고하자. https://kafka.apache.org/documentation/#producerconfigs
    return props;
}

@Bean
public KafkaTemplate<Integer, String> kafkaTemplate() {
    return new KafkaTemplate<Integer, String>(producerFactory());
}
```

버전 2.5부터, 이제 팩토리의 `ProducerConfig` 프로퍼티를 오버라이드하여 동일한 팩토리의 다양한 프로듀서 구성으로 템플릿을 생성할 수 있다.

```java
@Bean
public KafkaTemplate<String, String> stringTemplate(ProducerFactory<String, String> pf) {
    return new KafkaTemplate<>(pf);
}

@Bean
public KafkaTemplate<String, byte[]> bytesTemplate(ProducerFactory<String, byte[]> pf) {
    return new KafkaTemplate<>(pf,
            Collections.singletonMap(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, ByteArraySerializer.class));
}
```

`ProducerFactory<?, ?>` 타입(예: 스프링 부트에 의해 자동 구성된 빈)의 빈은 다른 일반 타입으로 참조될 수 있다.

표준 `<bean/>` 정의를 사용하여 템플릿을 구성할 수도 있다.

그 다음 템플릿을 사용하려면, 해당 메서드 중 하나를 호출하면 된다.

When you use the methods with a Message<?> parameter, the topic, partition, key and timestamp information is provided in a message header that includes the following items:

`Message<?>` 파라미터와 함께 메소드를 사용하면 토픽, 파티션, 키 및 타임스탬프 정보가 다음 항목을 포함하는 메시지 헤더에 제공된다.

- `KafkaHeaders.TOPIC`
- `KafkaHeaders.PARTITION`
- `KafkaHeaders.KEY`
- `KafkaHeaders.TIMESTAMP`

메시지 페이로드는 데이터다.

선택적으로, `Future`가 완료될 때까지 기다리는 대신 전송 결과(성공 또는 실패)와 함께 비동기(asynchronous) 콜백을 가져오도록 `ProducerListener`를 사용하여 `KafkaTemplate`을 구성할 수 있다. 다음 목록은 `ProducerListener` 인터페이스의 정의를 보여준다.

```java
public interface ProducerListener<K, V> {

    void onSuccess(ProducerRecord<K, V> producerRecord, RecordMetadata recordMetadata);

    void onError(ProducerRecord<K, V> producerRecord, RecordMetadata recordMetadata, Exception exception);

}
```

기본적으로, 템플릿은 오류를 기록하고 전송이 성공하면 아무 작업도 수행하지 않는 `LoggingProducerListener`로 구성된다.

편의를 위해 메소드 중 하나만 구현하려는 경우 기본 메소드 구현이 제공된다.

`send` 메소드는 `CompletableFuture<SendResult>`를 반환한다. 전송 결과를 비동기적으로 수신하기 위해 리스너에 콜백을 등록할 수 있다. 다음 예제에서는 그 방법을 보여준다.

```java
CompletableFuture<SendResult<Integer, String>> future = template.send("myTopic", "something");
future.whenComplete((result, ex) -> {
    ...
});
```

`SendResult`에는 `ProducerRecord`와 `RecordMetadata`라는 두 가지 프로퍼티가 있다. 해당 객체에 대한 자세한 내용은 카프카 API 설명서를 참고하자.

`Throwable`은 `KafkaProducerException`으로 캐스팅할 수 있다. `failedProducerRecord` 프로퍼티에는 실패한 레코드가 포함되어 있다.

결과를 기다리기 위해 전송 스레드를 차단하려면 `future`의 `get()` 메서드를 호출할 수 있다. 제한 시간이 있는 방법을 사용하는 것이 좋다. `linger.ms`를 설정한 경우 기다리기 전에 `flush()`를 호출할 수 있다. 또는 편의를 위해 템플릿에는 보낼 때마다 템플릿이 `flush()`되도록 하는 `autoFlush` 파라미터가 있는 생성자가 있다. `flush`는 `linger.ms` 프로듀서 프로퍼티을 설정하고 부분 배치를 즉시 보내려는 경우에만 필요하다.

